{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.info()  # confirmed no duplicate names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns, replace values, and create dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_data['Ticket'].unique()\n",
    "data_drop = raw_data.drop(['Name', 'Ticket'], axis = 1)\n",
    "data_drop.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drop['Sex'] = data_drop['Sex'].replace(['female', 'male'], [0, 1])\n",
    "data_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drop['Parch'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drop['SibSp'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drop['Pclass'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drop['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drop['Pclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drop_cabin = data_drop.drop('Cabin', axis=1)\n",
    "data_drop_cabin.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_columns = pd.get_dummies(data_drop_cabin['Pclass'], drop_first = True) # dummies for class\n",
    "class_columns = class_columns.rename(columns={2:'2nd Class', 3:'3rd Class'})\n",
    "data_class = pd.concat([data_drop_cabin, class_columns], axis=1).drop('Pclass', axis=1)\n",
    "data_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_columns = pd.get_dummies(data_class['Embarked'], drop_first = True) # dummies for embark\n",
    "embarked_columns = embarked_columns.rename(columns={'Q':'Queenstown', 'S':'Southampton'})\n",
    "data_dummy = pd.concat([data_class, embarked_columns], axis = 1).drop('Embarked', axis=1)\n",
    "data_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data_dummy['Fare']) # Fare has a couple outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_age = data_drop_cabin.dropna(how='any', axis=0)\n",
    "sns.set(context = 'paper')\n",
    "sns.stripplot(x=data_age['Survived'], y=data_age['Age'], hue = data_age['Pclass'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Embarked', y='Survived', data=data_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', data=data_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', ci = None, hue='Embarked', order=[3,2,1], data=data_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', hue='Sex', order=[3,2,1], data=data_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Numerical Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = pd.DataFrame()\n",
    "numerical_features['Scaled Age'] = data_dummy['Age']\n",
    "numerical_features['Scaled Fare'] = data_dummy['Fare']\n",
    "# numerical_features['Scaled SibSp'] = data_dummy['SibSp']\n",
    "# numerical_features['Scaled Parch'] = data_dummy['Parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(numerical_features)\n",
    "num_feat_scal = scaler.transform(numerical_features)\n",
    "num_feat_scal_df = pd.DataFrame(data=num_feat_scal, columns=['Age', 'Fare', \n",
    "#                                                              'SibSp', 'Parch'\n",
    "                                                            ])\n",
    "num_feat_scal_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dummy['Scaled Age'] = num_feat_scal_df['Age']\n",
    "data_dummy['Scaled Fare'] = num_feat_scal_df['Fare']\n",
    "data_scaled = data_dummy.drop(['Age', 'Fare'], axis=1)\n",
    "data_scaled.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Numbers to Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_scaled['Embarked'] = data_scaled['Embarked'].replace(['S', 'Q', 'C'], [1, 2, 3])\n",
    "# data_scaled.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN to Impute Missing Age Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=5)\n",
    "data_impute = imputer.fit_transform(data_scaled.drop('Survived', axis=1))\n",
    "data_impute = pd.DataFrame(data=data_impute, columns=['PassengerId', 'Sex', 'SibSp', 'Parch', '2nd Class',\n",
    "       '3rd Class', 'Queenstown', 'Southampton', 'Scaled Age',\n",
    "       'Scaled Fare'])\n",
    "\n",
    "data_impute.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_impute['Survived'] = data_scaled['Survived']\n",
    "data_impute.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Booleans for Familial Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resulted in model with worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def family_boolean(element):\n",
    "    if element > 1:\n",
    "        return int(1)\n",
    "    else:\n",
    "        return element\n",
    "\n",
    "data_impute['SibSp'] = pd.DataFrame(data_impute['SibSp'].apply(family_boolean)[0::], columns=['SibSp'])\n",
    "data_impute['SibSp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_impute['Parch'] = pd.DataFrame(data_impute['Parch'].apply(family_boolean)[0::], columns=['Parch'])\n",
    "data_impute['Parch'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Random Forest Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = ['Sex', 'SibSp', 'Parch', '2nd Class',\n",
    "       '3rd Class', 'Queenstown', 'Southampton', 'Scaled Age',\n",
    "       'Scaled Fare']\n",
    "\n",
    "features = data_impute[estimators]\n",
    "target = data_impute['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(random_state=0, n_jobs=-1, n_estimators = 100)\n",
    "model = randomforest.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "names = [estimators[i] for i in indices]\n",
    "plt.figure()\n",
    "plt.title('Feature Importance')\n",
    "plt.bar(range(len(estimators)), importances[indices])\n",
    "plt.xticks(range(features.shape[1]), names, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_drop = test_data.drop(['Name', 'Ticket', 'Cabin'], axis = 1)\n",
    "data_test_drop['Sex'] = data_test_drop['Sex'].replace(['female', 'male'], [0, 1])\n",
    "\n",
    "test_class = pd.get_dummies(data_test_drop['Pclass'], drop_first = True) # dummies for class\n",
    "test_class = test_class.rename(columns={2:'2nd Class', 3:'3rd Class'})\n",
    "data_test_class = pd.concat([data_test_drop, test_class], axis=1).drop('Pclass', axis=1)\n",
    "\n",
    "embarked_test_columns = pd.get_dummies(data_test_class['Embarked'], drop_first = True) # dummies for embark\n",
    "embarked_test_columns = embarked_test_columns.rename(columns={'Q':'Queenstown', 'S':'Southampton'})\n",
    "data_test_final = pd.concat([data_test_class, embarked_test_columns], axis = 1).drop('Embarked', axis=1)\n",
    "\n",
    "test_features = pd.DataFrame()\n",
    "test_features['Scaled Age'] = data_test_final['Age']\n",
    "test_features['Scaled Fare'] = data_test_final['Fare']\n",
    "\n",
    "test_feat_scal = scaler.transform(test_features)\n",
    "test_feat_scal_df = pd.DataFrame(data=test_feat_scal, columns=['Age', 'Fare'])\n",
    "\n",
    "data_test_final['Scaled Age'] = test_feat_scal_df['Age']\n",
    "data_test_final['Scaled Fare'] = test_feat_scal_df['Fare']\n",
    "data_test_scaled = data_test_final.drop(['Age', 'Fare'], axis=1)\n",
    "\n",
    "# data_test_scaled['Embarked'] = data_test_scaled['Embarked'].replace(['S', 'Q', 'C'], [1, 2, 3])\n",
    "\n",
    "data_test_scaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_impute = imputer.transform(data_test_scaled)\n",
    "data_test_impute = pd.DataFrame(data=data_test_impute, columns=['PassengerId', 'Sex', 'SibSp', 'Parch', '2nd Class',\n",
    "       '3rd Class', 'Queenstown', 'Southampton', 'Scaled Age',\n",
    "       'Scaled Fare'])\n",
    "data_test_impute.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_impute['SibSp'] = pd.DataFrame(data_test_impute['SibSp'].apply(family_boolean)[0::], columns=['SibSp'])\n",
    "data_test_impute['Parch'] = pd.DataFrame(data_test_impute['Parch'].apply(family_boolean)[0::], columns=['Parch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(data_test_impute[estimators])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export csv from formatted dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions, columns=['Predictions'])\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def assign_boolean(element):\n",
    "#     if element > 0.5:\n",
    "#         return int(1)\n",
    "#     else:\n",
    "#         return int(0)\n",
    "    \n",
    "# predictions_binary = predictions['Predictions'].apply(assign_boolean)[0::]\n",
    "# predictions_binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_final = pd.DataFrame(predictions_binary, columns=['Predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_export = pd.DataFrame()\n",
    "data_export['PassengerId'] = data_test_impute['PassengerId']\n",
    "data_export = data_export.astype('int32')\n",
    "data_export['Survived'] = predictions['Predictions']\n",
    "# data_export = pd.concat([data_test_final['PassengerId'], predictions_final['Predictions']])\n",
    "data_export.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_export.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_export.to_csv('Titanic_results_v5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Result: 0.76315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
